The output of emotions.py run on the folder: individual_round
The Cohen kappa score is: 0.1642788920725884

The confusion matrix is the following:
[[1 0 0 2 0 0 0 0 1 0]
 [2 0 0 0 0 0 0 0 0 0]
 [1 0 0 0 0 0 1 1 0 3]
 [3 0 0 6 0 0 0 0 0 0]
 [1 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 1]
 [0 1 0 4 0 3 7 0 1 1]
 [1 0 0 2 0 0 1 0 0 0]
 [0 0 0 0 0 0 0 0 1 0]
 [1 0 0 0 0 0 2 0 1 0]]

This kappa score is quite low. This means our annotations are not 
always similar. 

Recommendations for annotations tweets: 

Sometimes the tweets did not have a main emotion of feeling. 
Therefore the tweets were sometimes emotionless and just giving information
or stating facts.
There was not a annotation for those tweets. 
Furthermore some tweets had the possibility of being sarcasting, there was not a label for this Ã©motion'.
In this case often happy words were used to describe there feelings. 
So it can be possible that these tweets were annotated wrong and did not express joy or happiness at all,
but rather disgust or anger. 